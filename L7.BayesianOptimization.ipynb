{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational User Interface Design 2021\n",
    "\n",
    "## Bayesian Optimization\n",
    "[Original slides from a lecture at Aalto by Tomi Peltola](http://www.tmpl.fi/bayesian-optimization/slides.Rmd)\n",
    "\n",
    "---\n",
    "### Yi-Chi Liao\n",
    "\n",
    "Ph.D. candidate at User Interfaces (http://yichiliao.com).\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/3dtouch.png\" style=\"width: 90%\" />\n",
    "</div>\n",
    "\n",
    "Using multi-objective Bayesian optimization to optimize the 3D transfer function design.\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/button.png\" style=\"width: 90%\" />\n",
    "</div>\n",
    "Using multi-objective Bayesian optimization to optimize a touch button design.\n",
    "\n",
    "\n",
    "## Participants wanted!!\n",
    "\n",
    "- Possible dates: Wed (24th) - Fri (26th) / next Mon (29th) - next Wed (Dec 1st).\n",
    "- Duration: 2 - 3 hours.\n",
    "- Reward: 30 euro Fat Lizard Coupon.\n",
    "- Task: assist the designer to derive the optimal designs.\n",
    "- Ping me if you're interested! (yi-chi.liao@aalto.fi / telegram: hciresearch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "This is practically oriented lecture for HCI researchers and practitioners. After this lecture and the exercises, you should\n",
    "\n",
    " 1. understand the basics of Bayes Theorem,\n",
    " 2. understand the basics of Bayesian optimization and its applications in HCI,\n",
    " 2. be able to assess when it can be a useful tool and when not,\n",
    " 3. know how to use the GPyOpt Python package for your own applications.\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "\n",
    " 1. Introduction\n",
    " 2. Bayes Theorem\n",
    " 2. Bernoulli bandit\n",
    " 3. Bayesian optimization \n",
    " 4. Acquisition functions\n",
    " 5. Application example\n",
    " 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Introduction\n",
    "\n",
    "\n",
    "<p>\n",
    "<div class=\"alert alert-block alert-success\"> \n",
    "<h3>In-class exercise.</h3> \n",
    "<br>\n",
    "Ask your friend to pick one favorite color. You would like to figure out what they are, **but** you can only ask about one color at a time. When asked about a color, the friend must tell how liked it is on a scale from 1 to 5 (best). If you only have 8 questions, **how** should you choose which color to ask?</div>\n",
    "</p>\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/color_platte.png\" style=\"width: 90%\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "## Overview \n",
    "Bayesian optimization is a modern approach to **global optimization**. It is robust and sample-efficient and well-suited for noisy, expensive evaluative functions. It uses a **surrogate model** for approximating the model fit across the parameter space.  Posteriori probability provides an intuitive quantification of acquired knowledge of the best parameter values given the available observation data. Another core idea is to use an **acquisition rule** for selecting which parameter values are used for generating predictions, based on the surrogate model. Inference is performed through a sequence of optimization rounds. \n",
    "\n",
    "Recipe:\n",
    "\n",
    "- At the beginning of each round, the acquisition rule is used to select a set of parameter values that will be used to generate predictions. The locations are balanced such that they cover both unknown regions of the parameter space (**exploration**) and regions with high probability to lead to good model fit (**exploitation**). \n",
    "- After predictions have been generated at each location, the surrogate model is updated based on the observed model fits, and the next optimization round begins. \n",
    "- The final parameter estimates are often chosen to be the parameter values that lead to best predicted model fit on average.\n",
    "\n",
    "[Visual overview](imgs/bo-overview.png).\n",
    "Source: https://towardsdatascience.com\n",
    "\n",
    "**Compare: Grid search** assumes that the optimal parameter values are contained within some bounded region of the parameter space. Then divide this bounded parameter space into a large number of smaller cells, often by using an even grid. Then, for each grid cell, a dataset is generated using the parameter values at the cell, and finally the parameter values that yielded the best model fit are used as the final estimate.\n",
    "\n",
    "## Problem\n",
    "\n",
    "Find the minimum of a function $f(x)$ within some bounded domain $\\mathcal{X} \\subset \\mathbb{R}^D$:\n",
    "\n",
    "$$x^* = \\argmin_{x \\in \\mathcal{X}} f(x)$$\n",
    "\n",
    "**How would you solve this?**\n",
    "\n",
    " * Hand-tuning / trial and error,\n",
    " * random search,\n",
    " * grid search,\n",
    " * gradient descend,\n",
    " * evolutationary algorithms,\n",
    " * different types of programming (linear, integer, etc.),\n",
    " * ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - A/B testing\n",
    "\n",
    "But what if... $f$ \n",
    "\n",
    " * can only be evaluated implicitly,\n",
    " * with a lot of noise, and\n",
    " * is costly to evaluate.\n",
    " \n",
    "For example, optimize for click-through rate, retention time, or purchases, implicitly measuring user satisfaction, interest, or revenue of different version of a web site.\n",
    "\n",
    "By choosing conditions wisely, Bayesian optimization can converge to a good design quicker and avoid contaminating users with potentially bad designs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - Computational design\n",
    "\n",
    "But what if ... $f$ \n",
    "\n",
    " * is a black-box (e.g., contains human judgement),\n",
    " * with noisy and expensive/slow evaluations,\n",
    " * and multi-modal.\n",
    "\n",
    "For example, optimizing parameters for procedural animation generation by asking humans to rate generated examples.\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/anim.png\" style=\"width: 50%\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"font-size: 10px;\"><a href=\"https://dl.acm.org/citation.cfm?id=1921443\">[image: Brochu et al., 2010]</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - Adaptive interfaces\n",
    "\n",
    "But what if ... $f$ \n",
    "\n",
    " * is based on an implicit signal from human,\n",
    " * with noisy and expensive/slow evaluations.\n",
    "\n",
    "For example, optimizing step rate to minimize metabolic cost.\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/wearable_devices.png\" style=\"width: 70%\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"font-size: 10px;\"><a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184054\">[image: Kim et al., 2017]</a></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - Inverse modeling\n",
    "\n",
    "But what if ... $f$ \n",
    "\n",
    " * contains a parametric simulator,\n",
    " * with noisy and expensive/slow evaluations.\n",
    "\n",
    "For example, fitting parameters of cognitive simulators to experimental data.\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/abc2.png\" style=\"width: 60%\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"font-size: 10px;\"><a href=\"https://dl.acm.org/citation.cfm?doid=3025453.3025576\">[image: Kangasraasio et al., 2017]</a></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - Others\n",
    "\n",
    " * Recommender systems\n",
    " * Sensor networks\n",
    " * AutoML: automatic tuning of machine learning models\n",
    " * Robotics and reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The computational problem\n",
    "\n",
    "**Problem:** Find the minimum of a function $f(x)$ within some bounded domain $\\mathcal{X} \\subset \\mathbb{R}^D$:\n",
    "\n",
    "$$x^* = \\argmin_{x \\in \\mathcal{X}} f(x)$$\n",
    "\n",
    "**Challenges**\n",
    " * $f$ is a black-box that we can only evaluate point-wise, \n",
    " * $f$ can be multi-modal,\n",
    " * $f$ is slow or expensive to evaluate,\n",
    " * evaluations of $f$ are noisy,\n",
    " * $f$ has no gradients available (can be used if available).\n",
    "\n",
    "** Basic idea of BO **\n",
    "\n",
    "We want to find the minimum with small number of evaluations of $f$. Solution:\n",
    "\n",
    " 1. Construct a tractable **statistical surrogate model** of $f$.\n",
    " 2. Turn the optimization problem into **a sequence of easier problems**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bayes Theorem and Bayesian Inference<a id=\"2\">\n",
    "\n",
    "We have established a general understanding of Bayes Theorem and Bayesian inference in order to understand the core elements of Bayesian optimization.\n",
    "\n",
    "## 2.1 Conditional and  Joint Probability <a id=\"21\">\n",
    "\n",
    "### Joint Probability\n",
    "\n",
    "$P(A,B)$ is the probability two events $A$ and $B$ _both_ occurring.\n",
    "* For example, getting two heads in a row.\n",
    "\n",
    "If $A$ and $B$ are independent, then $P(A,B)=P(A)P(B)$ but be warned: this is not always (or often) the case.\n",
    "\n",
    "One way to think of this is considering \"AND\" as multiplication: the probability of A **and** B is the probability of A **multiplied** by the probability of B (if they are independent!).\n",
    "\n",
    "#### Hands-On: Joint Probability and Coin Flipping\n",
    "\n",
    "Verify that $P(A,B)=P(A)P(B)$ in the two fair coin-flip case (A=heads, B=heads) by \n",
    "- first simulating two coins being flipped together and calculating the proportion of occurences with two heads;\n",
    "- then simulating one coin flip and calculating the proportion of heads and then doing that again and multiplying the two proportions.\n",
    "\n",
    "Your two calculations should give \"pretty close\" results and not the same results due to the (in)accuracy of simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Hands-on: try to change the possibility of getting a head (1) and see what will happen\n",
    "x_0 = np.random.binomial(2, 0.5, 10000)\n",
    "p_ab = sum(x_0==2)/len(x_0)\n",
    "\n",
    "# Now, plot the histogram of the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(x_0)\n",
    "ax.set_xticks([0,1,2])\n",
    "print(p_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Calculate P(A)P(B)\n",
    "x_1 = np.random.binomial(__, 0.5, 10000)\n",
    "x_2 = np.random.binomial(__, 0.5, 10000)\n",
    "p_a = sum(x_1 == 1)/len(x_1)\n",
    "p_b = sum(x_2 == 1)/len(x_2)\n",
    "p_a*p_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probability\n",
    "\n",
    "Now that we have a grasp on joint probabilities, lets consider conditional probabilities, that is, the probability of some $A$, knowing that some other $B$ is true. We use the notation $P(A|B)$ to denote this.  \n",
    "\n",
    "Conditional and joint probabilites are related by the following:\n",
    "$$ P(A,B) = P(A|B)P(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Bayes Theorem <a id=\"22\">\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bayes](./imgs/bayes_theo2.png)\n",
    "\n",
    "### The cookie problem\n",
    "There are two bowls of cookies: \n",
    "- Bowl #1 has 10 chocolate and 30 vanilla\n",
    "- Bowl #2 has 20 chocolate and 20 vanilla\n",
    "\n",
    "You pick a bowl at random, and pick a cookie at random,\n",
    "the cookie turns out to be vanilla. \n",
    "\n",
    "\n",
    "What is the probability that you pick Bowl #1?\n",
    "\n",
    "`Pmf.from_seq` makes a `Pmf` object from a sequence of values.\n",
    "\n",
    "Here's how we can use it to create a `Pmf` with two equally likely hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empiricaldist import Pmf\n",
    "\n",
    "# This is prior\n",
    "cookie = Pmf.from_seq(['Bowl 1', 'Bowl 2'])\n",
    "cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type the likelihood\n",
    "cookie['Bowl 1'] *= ___\n",
    "cookie['Bowl 2'] *= ___\n",
    "cookie.normalize()\n",
    "cookie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-on: \n",
    "    \n",
    "Suppose we put the first cookie back, stir, choose again from the same bowl, and get a chocolate cookie.  \n",
    "What are the posterior probabilities after the second cookie?\n",
    "\n",
    "Hint: The posterior (after the first cookie) becomes the prior (before the second cookie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "cookie = Pmf.from_seq(['Bowl 1', 'Bowl 2'])\n",
    "cookie['Bowl 1'] *= ___\n",
    "cookie['Bowl 2'] *= ___\n",
    "cookie.normalize()\n",
    "cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_cookie(title):\n",
    "    \"\"\"Labels the axes.\n",
    "    \n",
    "    title: string\n",
    "    \"\"\"\n",
    "    plt.xlabel('Outcome')\n",
    "    plt.ylabel('PMF')\n",
    "    plt.title(title)\n",
    "\n",
    "cookie.bar()\n",
    "decorate_cookie('Outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dice problem\n",
    "\n",
    "Create a suite of hypotheses that represents dice with different numbers of sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice 4 has 4 faces, Dice 6 has 6 faces, ...\n",
    "dice = Pmf.from_seq([4, 6, 8, 12])\n",
    "dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll solve this problem two ways.  First we'll do it \"by hand\", as we did with the cookie problem; that is, we'll multiply each hypothesis by the likelihood of the data, and then renormalize.\n",
    "\n",
    "### Hands-on:\n",
    "In the space below, update `dice` based on the likelihood of the data (rolling a 6), then normalize and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "dice[4] *= ___\n",
    "dice[6] *= ___\n",
    "dice[8] *= ___\n",
    "dice[12] *= ___\n",
    "\n",
    "dice.normalize()\n",
    "dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-on:\n",
    "\n",
    "Now let's do the same calculation using `Pmf.update`, which encodes the structure of a Bayesian update.\n",
    "\n",
    "Define a function called `likelihood_dice` that takes `data` and `hypo` and returns the probability of the data (the outcome of rolling the die) for a given hypothesis (number of sides on the die).\n",
    "\n",
    "Hint: What should you do if the outcome exceeds the hypothetical number of sides on the die?\n",
    "\n",
    "Here's an outline to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_dice(data, hypo):\n",
    "    \"\"\"Likelihood function for the dice problem.\n",
    "    \n",
    "    data: outcome of the die roll\n",
    "    hypo: number of sides\n",
    "    \n",
    "    returns: float probability\n",
    "    \"\"\"\n",
    "    # TODO: fill this in!\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create a Pmf object and update it.\n",
    "\n",
    "dice = Pmf.from_seq([4, 6, 8, 12])\n",
    "dice.update(likelihood_dice, 6)\n",
    "dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-on:\n",
    "\n",
    "Create another Pmf object that update three times (got 6, 7, and 8). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "dice = Pmf.from_seq([4, 6, 8, 12])\n",
    "dice.update(likelihood_dice, __)\n",
    "dice.update(likelihood_dice, __)\n",
    "dice.update(likelihood_dice, __)\n",
    "dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Euro problem\n",
    "\n",
    "*\"When spun on edge 250 times, a Belgian one-euro coin came up heads 140 times and tails 110.  'It looks very suspicious to me,' said Barry Blight, a statistics lecturer at the London School of Economics.  'If the coin were unbiased, the chance of getting a result as extreme as that would be less than 7%.' \"*\n",
    "\n",
    "From “The Guardian” quoted by MacKay, *Information Theory, Inference, and Learning Algorithms*.\n",
    "\n",
    "\n",
    "### Hands-on:\n",
    "Write a function called `likelihood_euro` that defines the likelihood function for the Euro problem.  Note that `hypo` is in the range 0 to 100.\n",
    "\n",
    "Here's an outline to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_euro(data, hypo):\n",
    "    \"\"\" Likelihood function for the Euro problem.\n",
    "    \n",
    "    data: string, either 'H' or 'T'\n",
    "    hypo: prob of heads (0-100)\n",
    "    \n",
    "    returns: float probability\n",
    "    \"\"\"\n",
    "    # TODO: fill this in!\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_euro(title):\n",
    "    \"\"\"Labels the axes.\n",
    "    \n",
    "    title: string\n",
    "    \"\"\"\n",
    "    plt.xlabel('Probability of heads')\n",
    "    plt.ylabel('PMF')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro = Pmf.from_seq(range(101))\n",
    "euro.plot()\n",
    "decorate_euro('Prior distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can update with a single head:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro.update(likelihood_euro, 'H')\n",
    "euro.plot()\n",
    "decorate_euro('Posterior distribution, one heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another head:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro.update(likelihood_euro, 'H')\n",
    "euro.plot()\n",
    "decorate_euro('Posterior distribution, two heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a tail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro.update(likelihood_euro, 'T')\n",
    "euro.plot()\n",
    "decorate_euro('Posterior distribution, HHT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting over, here's what it looks like after 4 heads and 2 tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro = Pmf.from_seq(range(101))\n",
    "\n",
    "for outcome in 'HHHHTT':\n",
    "    euro.update(likelihood_euro, outcome)\n",
    "\n",
    "euro.plot()\n",
    "decorate_euro('Posterior distribution, 4 heads, 2 tails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro = Pmf.from_seq(range(101))\n",
    "\n",
    "evidence = 'H' * 140 + 'T' * 110\n",
    "for outcome in evidence:\n",
    "    euro.update(likelihood_euro, outcome)\n",
    "    \n",
    "euro.plot()\n",
    "\n",
    "decorate_euro('Posterior distribution, 140 heads, 110 tails')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swamping the prior\n",
    "\n",
    "The following function makes a Euro object with a triangle prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrianglePrior():\n",
    "    \"\"\"Makes a Suite with a triangular prior.\n",
    "    \"\"\"\n",
    "    suite = Pmf(name='triangle')\n",
    "    for x in range(0, 51):\n",
    "        suite[x] = x\n",
    "    for x in range(51, 101):\n",
    "        suite[x] = 100-x \n",
    "    suite.normalize()\n",
    "    return suite\n",
    "\n",
    "euro1 = Pmf.from_seq(range(101), name='uniform')\n",
    "euro1.plot()\n",
    "\n",
    "euro2 = TrianglePrior()\n",
    "euro2.plot()\n",
    "\n",
    "plt.legend()\n",
    "decorate_euro('Prior distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-on\n",
    "1. Update `euro1` and `euro2` with the same data (4 heads and 2 tails) and plot the posteriors.  How big is the difference in means?\n",
    "\n",
    "2. Update `euro1` and `euro2` with the same data (40 heads and 20 tails) and plot the posteriors.  How big is the difference in means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "evidence = ___\n",
    "for outcome in evidence:\n",
    "    euro1.update(likelihood_euro, outcome)\n",
    "    euro2.update(likelihood_euro, outcome)\n",
    "\n",
    "euro1.plot()\n",
    "euro2.plot()\n",
    "\n",
    "decorate_euro('Posterior distributions')\n",
    "plt.legend()\n",
    "\n",
    "euro1.mean(), euro2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "euro1 = Pmf.from_seq(range(101), name='uniform')\n",
    "\n",
    "euro2 = TrianglePrior()\n",
    "\n",
    "\n",
    "evidence = ___\n",
    "for outcome in evidence:\n",
    "    euro1.update(likelihood_euro, outcome)\n",
    "    euro2.update(likelihood_euro, outcome)\n",
    "\n",
    "euro1.plot()\n",
    "euro2.plot()\n",
    "\n",
    "decorate_euro('Posterior distributions')\n",
    "plt.legend()\n",
    "\n",
    "euro1.mean(), euro2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 From Bayes' Theorem to Bayesian Update <a id='23'>\n",
    "\n",
    "Let's say that we flip a biased coin several times and we want to estimate the probability of heads from the number of heads we saw. Statistical intuition tells us that our best estimate of $p(heads)=$ number of heads divided by total number of flips.\n",
    "\n",
    "However, \n",
    "\n",
    "1. It doesn't tell us how certain we can be of that estimate and\n",
    "2. This type of intuition doesn't extend to even slightly more complex examples.\n",
    "\n",
    "Bayesian inference helps us here. We can calculate the probability of a particular $p=p(H)$ given data $D$ by setting $A$ in Bayes Theorem equal to $p$ and $B$ equal to $D$.\n",
    "\n",
    "$$P(p|D) = \\frac{P(D|p)P(p)}{P(D)} $$\n",
    "  \n",
    "\n",
    "\n",
    "In this equation, we call $P(p)$ the prior (distribution), $P(D|p)$ the likelihood and $P(p|D)$ the posterior (distribution). The intuition behind the nomenclature is as follows: the prior is the distribution containing our knowledge about $p$ prior to the introduction of the data $D$ & the posterior is the distribution containing our knowledge about $p$ after considering the data $D$.\n",
    "\n",
    "  \n",
    "**Note** that we're _overloading_ the term _probability_ here. In fact, we have 3 distinct usages of the word:\n",
    "- The probability $p$ of seeing a head when flipping a coin;\n",
    "- The resulting binomial probability distribution $P(D|p)$ of seeing the data $D$, given $p$;\n",
    "- The prior & posterior probability distributions of $p$, encoding our _uncertainty_ about the value of $p$.\n",
    "\n",
    "**Key concept:** We only need to know the posterior distribution $P(p|D)$ up to multiplication by a constant at the moment: this is because we really only care about the values of $P(p|D)$ relative to each other – for example, what is the most likely value of $p$? To answer such questions, we only need to know what $P(p|D)$ is proportional to, as a function of $p$. Thus we don’t currently need to worry about the term $P(D)$. In fact,\n",
    "\n",
    "$$P(p|D) \\propto P(D|p)P(p) $$\n",
    "\n",
    "**Note:** What is the prior? Really, what do we know about $p$ before we see any data? Well, as it is a probability, we know that $0\\leq p \\leq1$. If we haven’t flipped any coins yet, we don’t know much else: so it seems logical that all values of $p$ within this interval are equally likely, i.e., $P(p)=1$, for $0\\leq p \\leq1$. This is known as an uninformative prior because it contains little information (there are other uninformative priors we may use in this situation, such as the Jeffreys prior, to be discussed later). People who like to hate on Bayesian inference tend to claim that the need to choose a prior makes Bayesian methods somewhat arbitrary, but as we’ll now see, if you have enough data, the likelihood dominates over the prior and the latter doesn’t matter so much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Bernoulli bandit\n",
    "\n",
    "*To link Bayesian optimization to Bayesian statistics, we look at a simpler, so-called bandit problem first.*\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/multi_armed_bandit.png\" style=\"width: 80%\" />\n",
    "</div>\n",
    "\n",
    "Illustration of a multi-armed bandit.\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/2_armed_bandit.png\" style=\"width: 80%\" />\n",
    "</div>\n",
    "\n",
    "Illustration of a two-armed bandit.\n",
    "\n",
    "**Task**: Conduct an A/B test to find which of two versions of a Web ad is better; that is, which ad gets most clicks.\n",
    "\n",
    "Problem setting:\n",
    " * **Experiment**: Show one of the two versions to a visitor.\n",
    " * **Observation**: Did the visitor click the ad.\n",
    " \n",
    "Minimize *regret* $R$ for $T$ experiments:\n",
    "$$R = T \\E[y^*] - \\sum_{t=1}^T y_t$$\n",
    " * $\\E[y^*]$ is the expected click rate for the better ad,\n",
    " * $y_t \\in \\{0,1\\}$ is whether visitor $t$, who was shown version $x_t \\in \\{A, B\\}$, clicked the ad.\n",
    "\n",
    " * Model click rates of $A$ and $B$ are $\\rho_A$ and $\\rho_B$, which are independent. Equations for A below.\n",
    " \n",
    "**Bayes theorem**: $p(\\theta \\mid \\mathcal{D}) = \\frac{p(\\mathcal{D} \\mid \\theta)}{p(\\mathcal{D})}  p(\\theta)$\n",
    "\n",
    "updates **prior** knowledge $p(\\theta)$ with **observations (likelihood)** $\\mathcal{D}$ to **posterior** knowledge $p(\\theta \\mid \\mathcal{D})$.\n",
    "\n",
    "Observation (likelihood) model:\n",
    "\n",
    "$$\\Pr(y_t \\mid x_t = A) = \\textrm{Bernoulli}(y_t \\mid \\rho_A) = \\rho_A^{y_t} (1 - \\rho_A)^{1-y_t}.$$\n",
    "\n",
    "Prior model:\n",
    "\n",
    "$$p(\\rho_A) = \\textrm{Beta}(\\rho_A \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\rho_A^{\\alpha-1} (1 - \\rho_A)^{\\beta-1}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset of $t$ observations $\\mathcal{D}_t = \\{(x_1, y_1), \\ldots, (x_t, y_t)\\}$, the posterior distribution is\n",
    "$$p(\\rho_A \\mid \\mathcal{D}_t) = \\frac{p(\\rho_A) \\prod_{t: x_t = A} \\Pr(y_t \\mid x_t = A)}{\\int_0^1 p(\\rho_A) \\prod_{t: x_t = A} \\Pr(y_t \\mid x_t = A) d\\rho_A} = \\textrm{Beta}(\\rho_B \\mid \\alpha + n^{A}_1, \\beta + n^{A}_0),$$\n",
    "where $n^{A}_1$ and $n^{A}_0$ are the total numbers of $y_t = 1$ and $y_t = 0$ for $x_t = A$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 101)\n",
    "\n",
    "# Create a uniform distribution using beta distribution\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, __, __), 'b-', label='Prior Beta(__,__)')\n",
    "plt.xlabel(r'Click rate $\\rho_A$')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, __, __), 'b-', label='Prior Beta(__,__)')\n",
    "plt.plot(x, __, 'r-', label='Observation model for y_1=1')\n",
    "plt.xlabel(r'Click rate $\\rho_A$')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, 1, 1), 'b-', label='Prior Beta(1,1)')\n",
    "plt.plot(x, x, 'r-', label='Observation model for y_1=1')\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, ___, ___), 'k-', label='Posterior Beta(2,1)')\n",
    "plt.xlabel(r'Click rate $\\rho_A$')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, 1, 1), 'b-', label='Prior Beta(1,1)')\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, ___, ___), 'k-', label='Posterior Beta(2,5)')\n",
    "plt.xlabel(r'Click rate $\\rho_A$')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Thompson sampling\n",
    "\n",
    "When $t+1$th visitor comes, which ad, $A$ or $B$, to serve?\n",
    "\n",
    " * Want to exploit: gather as much clicks as possible.\n",
    " * Need to explore: learn about click rates for $A$ and $B$.\n",
    " \n",
    "Questions:\n",
    "- What is the issue of pure explit strategy?\n",
    "- What is the issue of pure explore strategy?\n",
    "- What is your solution?\n",
    " \n",
    "Thompson sampling is a simple algorithm navigating this trade-off:\n",
    "\n",
    " 1. Sample a value for $\\hat{\\rho}_A$ and for $\\hat{\\rho}_B$ from $p(\\rho_A \\mid \\mathcal{D}_t)$ and $p(\\rho_B \\mid \\mathcal{D}_t)$.\n",
    " 2. Show $A$ if $\\hat{\\rho}_A > \\hat{\\rho}_B$ and $B$ otherwise.\n",
    " \n",
    "We then observe whether the visitor clicked the ad or not and update our posterior distributions and continue to next iteration.\n",
    "\n",
    "## Example \n",
    "*How does Thompson sampling navigate exploration-exploitation trade-off?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rho_A_true = 0.1; rho_B_true = 0.2 # simulated visitor click rates\n",
    "alpha = 1; beta = 1 # prior parameters\n",
    "n_A1 = 0; n_A0 = 0; n_B1 = 0; n_B0 = 0 # numbers of clicks/no-clicks\n",
    "T = 1000 # number of iterations\n",
    "clicks = np.zeros(T); A_or_B = np.zeros(T)\n",
    "\n",
    "for t in range(T):\n",
    "    # Thompson sampling\n",
    "    rho_A = np.random.beta(___, ___)\n",
    "    rho_B = np.random.beta(___, ___)\n",
    "    if rho_A > rho_B: # which ad to show\n",
    "        y_t = np.random.binomial(1, rho_A_true) # simul. click\n",
    "        n_A1 += __; n_A0 += __; # update posterior of A\n",
    "    else:\n",
    "        y_t = np.random.binomial(1, rho_B_true) # simul. click\n",
    "        n_B1 += __; n_B0 += __; # update posterior of B\n",
    "    # collect statistics\n",
    "    clicks[t] = y_t; A_or_B[t] = rho_A > rho_B\n",
    "    \n",
    "# instead of Thompson sampling, allocate same numbers to A and B\n",
    "clicks_half = np.zeros(T)\n",
    "\n",
    "for t in range(T):\n",
    "    if t % 2 == 0:\n",
    "        y_t = np.random.binomial(1, rho_A_true)\n",
    "    else:\n",
    "        y_t = np.random.binomial(1, rho_B_true)\n",
    "    clicks_half[t] = y_t\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(range(1,T+1), np.cumsum(clicks), 'r-', label='Thompson sampling')\n",
    "plt.plot(np.array(range(1,T+1))[A_or_B==1], np.cumsum(clicks)[A_or_B==1], 'k.', label='Thompson sampling chose A')\n",
    "plt.plot(range(1,T+1), np.cumsum(clicks_half), 'b-', label='Half A, half B')\n",
    "plt.plot(range(1,T+1), np.array(range(1,T+1)) * rho_B_true, 'k-', label='Always B (theoretical average)')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('Cumulative number of clicks')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Bayesian Optimization\n",
    "\n",
    "## Task\n",
    "\n",
    "Find the minimum of a function $f(x)$ within some bounded domain $\\mathcal{X} \\subset \\mathbb{R}^D$:\n",
    "\n",
    "$$x^* = \\argmin_{x \\in \\mathcal{X}} f(x)$$\n",
    "\n",
    "Want to find the minimum with small number of evaluations of $f$.\n",
    "\n",
    " 1. **Construct a tractable statistical surrogate model of $f$.**\n",
    " 2. Turn the optimization problem into a sequence of easier problems.\n",
    "\n",
    "## 4.1 Surrogate models\n",
    "\n",
    "\"A **surrogate model** is an engineering method used when an outcome of interest cannot be easily directly measured, so a model of the outcome is used instead.\" (Wikipedia)\n",
    " \n",
    "Let $g(x)$ be our **surrogate model** of $f$.\n",
    "\n",
    " * $g$ should be able to capture important aspects of $f$ from small number of evaluations.\n",
    " * Need to be able to update $g$ when we acquire new evaluations of $f$: $g$ should get better and better as a model of $f$.\n",
    " * $g$ should be fast to evaluate and to update.\n",
    " * $g$ needs to cope with noise.\n",
    " * Need to be able to quantify uncertainty in $g$ (navigating exploration-exploitation tradeoff).\n",
    "\n",
    "### Gaussian processes\n",
    "\n",
    "Gaussian process (GP) regression models are commonly used surrogate models used in BO. This is because of its capacity to approximate a large subset of model fit surfaces that are encountered in practice. GP models are also able to model the stochasticity of model fit, thus allowing a principled estimation of its mean and variance everywhere in the parameter search space.\n",
    "\n",
    " * Gaussian processes provide a probability distribution over functions.\n",
    " * Extends (and uses properties of) the multivariate normal distribution $\\Rightarrow$ computationally tractable.\n",
    " * Prior information about the type or behaviour of the modelled function can be included in the *covariance function* and its parameters.\n",
    " \n",
    " * Alternatives: random forests, Bayesian neural networks.\n",
    " \n",
    "<p>\n",
    "<div class=\"alert alert-block alert-success\"> \n",
    "<h3>In-class exercise.</h3> \n",
    "<br>\n",
    "Open the [Interactive demo app](http://www.infinitecuriosity.org/vizgp/).</div>\n",
    "</p>\n",
    "<div id=\"gp-outer\"></div>\n",
    "\n",
    "\n",
    "## 4.2 Turn the optimization problem into a sequence of easier problems\n",
    "\n",
    "Consider having evaluated $f$ at points $x_1, \\ldots, x_{t-1}$ and having constructed $p(g \\mid \\mathcal{D}_{t-1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy; import GPyOpt\n",
    "\n",
    "def f_u(x):\n",
    "    return x**2 + 0.1 + 0.1 * np.random.randn()\n",
    "bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (0,1)}]\n",
    "myBopt = GPyOpt.methods.BayesianOptimization(\n",
    "    f=f_u, domain=bounds, acquisition_type='EI',\n",
    "    exact_feval = False, initial_design_numdata=2, normalize_Y=False)\n",
    "max_iter = 0; max_time = 60; eps = 10e-6\n",
    "\n",
    "# Try to change the initial number from 2 to 4\n",
    "\n",
    "myBopt.run_optimization(max_iter, eps)\n",
    "myBopt._update_model()\n",
    "#myBopt.plot_acquisition()\n",
    "#myBopt.model.model.plot([0.0,1.0])\n",
    "model = myBopt.model.model\n",
    "\n",
    "x_grid = np.arange(0, 1, 0.001)\n",
    "x_grid = x_grid.reshape(len(x_grid),1)\n",
    "m, v = model.predict(x_grid)\n",
    "\n",
    "model.plot_density([0,1], alpha=.5)\n",
    "\n",
    "plt.plot(x_grid, m, 'k-',lw=1,alpha = 0.6)\n",
    "plt.plot(x_grid, m-1.96*np.sqrt(v), 'k-', alpha = 0.2)\n",
    "plt.plot(x_grid, m+1.96*np.sqrt(v), 'k-', alpha=0.2)\n",
    "\n",
    "Xdata, Ydata = myBopt.get_evaluations()\n",
    "\n",
    "plt.plot(Xdata, Ydata, 'r.', markersize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to choose the next $x$ to evaluate $f$ at?\n",
    "\n",
    "**What would you do?**\n",
    "\n",
    "Consider having evaluated $f$ at points $x_1, \\ldots, x_{t-1}$ and having constructed $p(g \\mid \\mathcal{D}_{t-1})$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n",
    "# 5. Acquisition functions \n",
    "How to choose the next $x$ to evaluate $f$ at?\n",
    "\n",
    "\n",
    "**Thompson sampling** acquisition function:\n",
    "\n",
    " * $\\alpha(x; \\mathcal{D}_{t-1}) = \\hat{g}(x)$, where $\\hat{g}(x)$ is a sample from $p(g \\mid \\mathcal{D}_{t-1})$.\n",
    "\n",
    "**Expected improvement** acquisition function:\n",
    "\n",
    " * Currently best value $y^* = \\max_{s \\in \\{1,\\ldots,t-1\\}} y_s$.\n",
    " * Improvement function provides utility of $x$ given $g$: $I(x, g) = (g(x) - y^*) I(g(x) > y^*)$.\n",
    " * Expected improvement: $\\alpha_{EI}(x; \\mathcal{D}_t) = \\E_g[I(x, g)]$.\n",
    "\n",
    "Many others also exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization Recipe\n",
    "\n",
    "**Goal**: Find the minimum of a function $f(x)$ within some bounded domain $\\mathcal{X} \\subset \\mathbb{R}^D$:\n",
    "\n",
    "$$x^* = \\argmin_{x \\in \\mathcal{X}} f(x)$$\n",
    "\n",
    "**Key ideas**\n",
    "\n",
    " 1. Construct a tractable statistical surrogate model of $f$.\n",
    " 2. Turn the optimization problem into a sequence of easier problems.\n",
    "\n",
    "**Algorithm**\n",
    "\n",
    " 1. Initialize dataset $\\mathcal{D}_0$, surrogate model $p(g \\mid \\mathcal{D}_0)$; choose acquisition function $\\alpha(\\cdot)$.\n",
    " 2. Loop for $t = 1,2,\\ldots,T$:\n",
    "      1. Select next evaluation point: $x_{t} = \\argmax \\alpha(x; \\mathcal{D}_{t-1})$.\n",
    "      2. Evaluate $f(x_{t})$ to obtain $y_{t}$.\n",
    "      3. Update dataset $\\mathcal{D}_{t} = \\{\\mathcal{D}_{t-1},(x_t, y_t)\\}$.\n",
    "      4. Update surrogate model $p(g \\mid \\mathcal{D}_t)$.\n",
    " 3. Report the found optimum.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPyOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_u(x):\n",
    "    return 0.2 * (x - 0.3)**2 - 0.4 * np.sin(15.0 * x)\n",
    "\n",
    "plt.figure(); xx = np.linspace(0, 1, 101)\n",
    "plt.plot(xx, f_u(xx), 'k-'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (0,1)}]\n",
    "myBopt = GPyOpt.methods.BayesianOptimization(\n",
    "    f=f_u, domain=bounds,        # Function and domain                 \n",
    "    acquisition_type='EI',       # Expected improvement\n",
    "    exact_feval=True,            # Noiseless function evaluations\n",
    "    eps=1e-6,\n",
    "    normalize_Y=False,           # (for clearer visualization)\n",
    "    initial_design_numdata=2)    # (for clearer visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt.run_optimization(max_iter=1)\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt.run_optimization(max_iter=1)\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt.run_optimization(max_iter=1)\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt.run_optimization(max_iter=1)\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt.run_optimization(max_iter=1)\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does it work?\n",
    "\n",
    " * Theoretical guarantees (regret bounds) exists under some conditions.\n",
    " * ''There is still a wide gap between theory and practice.'' - Shahriari et al.\n",
    "\n",
    "''[...]the careful choice of statistical model is often far more important than the choice of acquisition function heuristic.'' - Shahriari et al.\n",
    "\n",
    "**Some limitations**\n",
    "\n",
    " * Difficult for high-dimensional spaces.\n",
    " * Can spend a lot of time on the edges of the space (Siivola et al., MLSP 2018).\n",
    " * Computation complexity of inference in Gaussian processes scales as $O(N^3)$, where $N$ is the number of observations (sparse GPs/inducing point approximations can be used; or other types of models).\n",
    " * Optimizing hyperparameters (controlling the behaviour of the surrogate) can be challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Application example\n",
    "\n",
    "Two types of rather direct human-in-the-loop applications:\n",
    " * Human provides explicit feedback at $x$, the value $f(x)$.\n",
    " * Human provides implicit feedback at $x$, for example, $f(x)$ is a completion time of a task with parameters $x$.\n",
    "\n",
    "## Animation design\n",
    "\n",
    "Find parameters for generating a procedural fluid animation:\n",
    "* velocity, radius and magnitude of the (possibly multiple) vortex rings,\n",
    "* length scale and magnitude of the curl noise,\n",
    "* relative strengths of vortex rings and curl noise.\n",
    "\n",
    "User can easily tell which animations look good: ''the psychoperceptual process underlying judgment - how well a realization fits what the user has in mind''.\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/anim.png\" style=\"width: 50%\" />\n",
    "</div>\n",
    "\n",
    "*Eric Brochu, Tyson Brochu, Nando de Freitas: A Bayesian Interactive Optimization Approach to Procedural Animation Design, Eurographics/ACM SIGGRAPH Symposium on Computer Animation (2010).*\n",
    "\n",
    "### User interface\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/ui.png\" style=\"width: 79%\" />\n",
    "</div>\n",
    "\n",
    "### Algorithm\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/bo_alg.png\" style=\"width: 79%\" />\n",
    "</div>\n",
    "\n",
    "### User study\n",
    " * Obtained improved results compared to novice and expert users setting parameters manually.\n",
    " * Tailored the Bayesian optimization approach to make it work:\n",
    "      1. preferential feedbacks,\n",
    "      2. transfer information over multiple sessions,\n",
    "      3. com-bined manual parameter tuning and Bayesian optimization.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# In-class exercise: Eliciting color preferences\n",
    "\n",
    "<p>\n",
    "<div class=\"alert alert-block alert-success\"> \n",
    "<h3>In-class exercise.</h3> \n",
    "<br>\n",
    "Below is a script that implements the color preference elicitation problem. It asks 8 questions. Can you figure out how to improve it?  \n",
    "<br>\n",
    "<b>Tip:</b> Can you improve the acquisition function? Three things to try are: \n",
    "‘EI’, expected improvement;\n",
    "‘MPI’, maximum probability of improvement; and\n",
    "‘LCB’, GP-Lower confidence bound. \n",
    "[Manual page](https://gpyopt.readthedocs.io/en/latest/GPyOpt.methods.html)\n",
    "</div>\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def f_u(x):\n",
    "    plt.figure(1)\n",
    "    print(x)\n",
    "    im = x.reshape(1, 1, 3).repeat(3, axis=0).repeat(3, axis=1)\n",
    "    plt.imshow(im)\n",
    "    plt.show(block=False)\n",
    "    while True:\n",
    "        res = input('Grade? (0 to 5) ')\n",
    "        if res in ['0', '1', '2', '3', '4', '5']:\n",
    "            res = int(res)\n",
    "            plt.close(1)\n",
    "            return res\n",
    "\n",
    "\n",
    "def run_bo(max_iter):\n",
    "    bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (0, 1)},\n",
    "              {'name': 'var_2', 'type': 'continuous', 'domain': (0, 1)},\n",
    "              {'name': 'var_2', 'type': 'continuous', 'domain': (0, 1)}]\n",
    "    myBopt = GPyOpt.methods.BayesianOptimization(\n",
    "        f=f_u, domain=bounds,\n",
    "        acquisition_type='MPI',\n",
    "        exact_feval=False,\n",
    "        eps=1e-6,\n",
    "        normalize_Y=False,\n",
    "        initial_design_numdata=2,\n",
    "        maximize=True)\n",
    "    myBopt.run_optimization(max_iter=max_iter - 2)\n",
    "\n",
    "    return myBopt\n",
    "\n",
    "\n",
    "def run_random(max_iter):\n",
    "    xs = np.zeros((max_iter, 3))\n",
    "    ys = np.zeros((max_iter,))\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        xs[i, :] = np.random.rand(3)\n",
    "\n",
    "        ys[i] = f_u(xs[i, :])\n",
    "\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_iter = 8\n",
    "    # run BO\n",
    "    bo = run_bo(n_iter)\n",
    "    # run random for comparison\n",
    "    ra = run_random(n_iter)\n",
    "\n",
    "    bo_xs, bo_ys = bo.get_evaluations()\n",
    "    ra_xs, ra_ys = ra\n",
    "\n",
    "    # one can investigate these to see how good colors were found and compare\n",
    "    # to a ground truth color\n",
    "\n",
    "    plt.plot(-bo_ys, 'k-', label='BO')\n",
    "    plt.plot(ra_ys, 'r-', label='Random')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('grades')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # let's say ground truth color was red\n",
    "    x_gt = np.array([1.0, 0.0, 0.0])\n",
    "\n",
    "    plt.plot(np.sqrt(np.sum((bo_xs - x_gt)**2, 1)), 'k-', label='BO')\n",
    "    plt.plot(np.sqrt(np.sum((ra_xs - x_gt)**2, 1)), 'r-', label='Random')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('distance from ground truth')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 6. Conclusion \n",
    "\n",
    "## Summary\n",
    "Find the minimum of a function $f(x)$ within some bounded domain $\\mathcal{X} \\subset \\mathbb{R}^D$:\n",
    "\n",
    "$$x^* = \\argmin_{x \\in \\mathcal{X}} f(x)$$\n",
    "\n",
    " * $f$ is a black-box that we can only evaluate point-wise, \n",
    " * $f$ can be multi-modal,\n",
    " * $f$ is slow or expensive to evaluate,\n",
    " * evaluations of $f$ are noisy,\n",
    " * $f$ has no gradients available (can be used if available).\n",
    "\n",
    "**Key ideas**\n",
    "\n",
    " 1. Construct a tractable statistical surrogate model of $f$, with proper uncertainty quantification.\n",
    " 2. Turn the optimization problem into a sequence of easier problems, navigating the exploration-exploitation tradeoff.\n",
    "\n",
    "\n",
    "**Wide range of applications**. Relevant for HCI and human-in-the-loop modelling.\n",
    "\n",
    "Many **software implementations** (e.g., GPyOpt) exists. Relatively easy to start using.\n",
    "\n",
    "## Readings\n",
    " * <a href=\"https://ieeexplore.ieee.org/document/7352306\">Shahriari et al., **Taking the Human Out of the Loop: A Review of Bayesian Optimization**, Proceedings of the IEEE, 2016.</a>\n",
    " * <a href=\"http://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb\">Cam Davidson-Pilon, **Chapter 1: Introduction to Bayesian Methods from Bayesian Methods for Hackers**.<a/>\n",
    " * <a href=\"http://www.gaussianprocess.org/gpml/\">Rasmussen, Williams, **Gaussian Processes for Machine Learning**, MIT Press, 2016.</a>\n",
    " * <a href=\"http://sheffieldml.github.io/GPyOpt/\">GPyOpt, Python package for Bayesian optimization.</a>\n",
    " * <a href=\"http://www.tmpl.fi/gp/\">Interactive Gaussian process regression demo.</a>\n",
    " * <a href=\"https://dl.acm.org/citation.cfm?id=1921443\">Brochu et al., **A Bayesian Interactive Optimization Approach to Procedural Animation Design**, Eurographics/ACM SIGGRAPH Symposium on Computer Animation, 2010.</a>.\n",
    " * <a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184054\">Kim et al., **Human-in-the-loop Bayesian optimization of wearable device parameters**, PLOS ONE, 2017.</a>\n",
    " * <a href=\"https://dl.acm.org/citation.cfm?doid=3025453.3025576\">Kangasraasio et al., **Inferring Cognitive Models from Data using Approximate Bayesian Computation**, CHI 2017.</a>\n",
    " * <a href=\"https://arxiv.org/abs/1704.00963\">Siivola et al., **Correcting boundary over-exploration deficiencies in Bayesian optimization with virtual derivative sign observations**, MLSP 2018.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
